# Week 2: Data Collection from Real Usage - Checklist

> Gather empirical evidence of pattern effectiveness through real marketplace transactions

**Goal:** By end of Week 2, you'll have 100+ real transactions with bidirectional ratings, statistical analysis, and documented edge cases.

**Time Budget:** 20 hours (4 hours/day × 5 days)
**Status:** Not started
**Current Date:** October 28, 2025

---

## Pre-Week 2 Verification

- [ ] Confirm Week 1 is complete (all tests passing)
- [ ] Verify current deployment status on Fuji testnet
- [ ] Check all 53 agents are registered and funded
- [ ] Review base_agent.py bidirectional methods
- [ ] Understand current agent ecosystem

**Estimated Time:** 1 hour
**Output:** Clear understanding of current system state

---

## Day 1: Deploy Bidirectional Code to All Agents (4 hours)

### Morning: Verify System Agents (1 hour)
- [ ] Check karma-hello has bidirectional rating methods
- [ ] Check abracadabra has bidirectional rating methods
- [ ] Check skill-extractor has bidirectional rating methods
- [ ] Check voice-extractor has bidirectional rating methods
- [ ] Check validator has bidirectional rating methods

**Files to verify:**
- `agents/karma-hello/main.py`
- `agents/abracadabra/main.py`
- `agents/skill-extractor/main.py`
- `agents/voice-extractor/main.py`
- `agents/validator/main.py`

### Update User Agent Template (2 hours)
- [ ] Update `client-agents/template/main.py` with bidirectional rating
- [ ] Add `rate_seller()` method for clients to rate services
- [ ] Add `get_my_ratings()` method to view received ratings
- [ ] Test template with one user agent

**Files to modify:**
- `client-agents/template/main.py`

### Propagate to All 48 User Agents (1 hour)
- [ ] Create script: `scripts/update_all_user_agents.py`
- [ ] Script should:
  - Copy template changes to all 48 user agent folders
  - Preserve individual agent addresses and configs
  - Validate each agent after update
- [ ] Run propagation script
- [ ] Verify random sample of 5 agents

**Commands:**
```bash
python scripts/update_all_user_agents.py --dry-run
python scripts/update_all_user_agents.py --apply
python scripts/verify_user_agents.py --check-bidirectional
```

**Acceptance Criteria:**
- [ ] All 5 system agents have bidirectional methods
- [ ] All 48 user agents have bidirectional methods
- [ ] Verification script confirms all agents ready

**Output:** `contribution/week2/2.1-DAY1-DEPLOYMENT.md`

---

## Day 2: Create Marketplace Simulation Script (4 hours)

### Design Simulation Scenarios (1 hour)
- [ ] Scenario 1: Good client + good seller (both rate 5/5)
- [ ] Scenario 2: Bad client (late payment, seller rates 1/5)
- [ ] Scenario 3: Bad seller (poor quality, client rates 1/5)
- [ ] Scenario 4: Disputed transaction (asymmetric ratings)
- [ ] Scenario 5: Validator disagreement (seller rates validator low)
- [ ] Scenario 6: Multiple transactions (rating history buildup)

### Implement Simulation Script (3 hours)
- [ ] Create `scripts/simulate_marketplace.py`
- [ ] Script should:
  - Load all 53 agent configs
  - Execute predefined transaction scenarios
  - Include bidirectional ratings for each transaction
  - Log transaction hashes
  - Export results to CSV
  - Generate summary statistics

**Script structure:**
```python
# scripts/simulate_marketplace.py
import argparse
from shared.base_agent import ERC8004BaseAgent
from shared.agent_config import load_agent_config

def simulate_good_transaction(buyer, seller):
    """Both parties satisfied - mutual 5/5 ratings"""
    # 1. Buyer purchases from seller
    # 2. Buyer rates seller: 5/5
    # 3. Seller rates buyer: 5/5
    return tx_data

def simulate_bad_client(buyer, seller):
    """Client problematic - seller rates low"""
    # 1. Buyer purchases from seller
    # 2. Buyer rates seller: 5/5 (happy with service)
    # 3. Seller rates buyer: 1/5 (client was difficult)
    return tx_data

# ... more scenarios
```

**Acceptance Criteria:**
- [ ] Script runs without errors (dry-run mode)
- [ ] All 6 scenarios implemented
- [ ] Transaction data logged clearly
- [ ] CSV export format defined

**Output:** `scripts/simulate_marketplace.py` ready for execution

---

## Day 3: Execute Marketplace Transactions (4 hours)

### Execute Test Transactions (3 hours)
- [ ] Run simulation: 20 good transactions
- [ ] Run simulation: 10 bad client scenarios
- [ ] Run simulation: 10 bad seller scenarios
- [ ] Run simulation: 20 disputed transactions
- [ ] Run simulation: 20 validator rating scenarios
- [ ] Run simulation: 20 multi-transaction histories

**Total:** 100 transactions across 6 scenario types

**Commands:**
```bash
# Dry run first
python scripts/simulate_marketplace.py --dry-run --transactions 100

# Execute for real
python scripts/simulate_marketplace.py --execute --transactions 100 --output data/week2_transactions.csv
```

### Verify On-Chain (1 hour)
- [ ] Check random sample of 10 transactions on Snowtrace
- [ ] Verify events emitted correctly
- [ ] Confirm ratings stored on-chain
- [ ] Screenshot key transactions for documentation

**Acceptance Criteria:**
- [ ] 100+ transactions successfully executed
- [ ] All visible on Snowtrace
- [ ] CSV export contains all transaction data
- [ ] No failed transactions

**Outputs:**
- `contribution/week2/data/transactions.csv`
- `contribution/week2/data/transaction_hashes.txt`
- `contribution/week2/screenshots/`

---

## Day 4: Analyze Rating Patterns (4 hours)

### Statistical Analysis (3 hours)
- [ ] Import transaction data into analysis notebook
- [ ] Calculate metrics:
  - Average rating by direction (buyer→seller, seller→buyer)
  - Rating correlation (are mutual high ratings common?)
  - Asymmetry detection (transactions where ratings differ >2 points)
  - Validator rating distribution
- [ ] Create visualizations:
  - Histogram of rating differences
  - Scatter plot: buyer rating vs seller rating
  - Network graph showing rating flows
- [ ] Generate summary statistics

**Files to create:**
- `contribution/week2/analysis/rating_patterns.ipynb`
- `contribution/week2/analysis/statistics.json`

**Analysis script structure:**
```python
import pandas as pd
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv('contribution/week2/data/transactions.csv')

# Calculate correlation
correlation = df[['buyer_rating', 'seller_rating']].corr()

# Identify asymmetric ratings
asymmetric = df[abs(df['buyer_rating'] - df['seller_rating']) > 2]

# ... more analysis
```

### Document Key Findings (1 hour)
- [ ] Write analysis summary
- [ ] Highlight interesting patterns
- [ ] Identify edge cases
- [ ] Compare to baseline expectations

**Acceptance Criteria:**
- [ ] Statistical analysis complete
- [ ] Key findings documented
- [ ] Visualizations clear and informative

**Output:** `contribution/week2/2.4-DAY4-ANALYSIS-RESULTS.md`

---

## Day 5: Document Edge Cases (4 hours)

### Identify Edge Cases from Data (2 hours)
- [ ] Find transaction: Client rates 5/5, seller rates 1/5
- [ ] Find transaction: Seller rates 1/5, client rates 5/5
- [ ] Find transaction: Validator gives low score, seller disputes
- [ ] Find transaction: Client never completes purchase (fraud)
- [ ] Find transaction: Multiple ratings between same parties
- [ ] Find transaction: Rating update (agent changes rating)

### Document Each Edge Case (2 hours)
- [ ] For each edge case, document:
  - Transaction hash
  - On-chain data (Snowtrace screenshot)
  - Why this is interesting
  - How bidirectional trust helps
  - Link to transaction on Snowtrace

**Files to create:**
- `contribution/week2/2.5-EDGE-CASES.md`

**Edge case documentation template:**
```markdown
### Edge Case: Bad Faith Client

**Transaction Hash:** 0x...
**Scenario:** Client received excellent service but was difficult
**Ratings:**
- Client → Seller: 5/5 (happy with service)
- Seller → Client: 1/5 (client was rude, delayed payment)

**Why This Matters:**
Without bidirectional trust, this client would appear to have good transactions (5/5 rating to seller), but sellers would avoid them due to their 1/5 client rating.

**On-Chain Proof:** [Snowtrace Link]
**Screenshot:** ![](screenshots/bad_client_example.png)
```

**Acceptance Criteria:**
- [ ] At least 6 edge cases documented
- [ ] Each edge case has on-chain proof
- [ ] Screenshots included
- [ ] Analysis explains significance

**Output:** `contribution/week2/2.5-EDGE-CASES.md`

---

## Week 2 Deliverables Checklist

### Code & Scripts
- [ ] All 53 agents updated with bidirectional rating methods
- [ ] Marketplace simulation script (`scripts/simulate_marketplace.py`)
- [ ] Analysis notebook (`contribution/week2/analysis/rating_patterns.ipynb`)
- [ ] All scripts committed and pushed

### Transaction Data
- [ ] 100+ transactions executed on Fuji testnet
- [ ] Transaction CSV export
- [ ] Transaction hash list
- [ ] Screenshots of key transactions

### Analysis & Documentation
- [ ] Statistical analysis complete
- [ ] Rating pattern findings documented
- [ ] Edge cases documented (6+)
- [ ] Week 2 summary written

### Progress Tracking
- [ ] Updated `contribution/0.2-PROGRESS-TRACKER.md`
- [ ] Week 2 retrospective completed
- [ ] Ready to start Week 3

---

## Success Criteria for Week 2

**You're ready for Week 3 when:**
1. ✅ All 53 agents have bidirectional rating methods
2. ✅ 100+ transactions executed successfully
3. ✅ Transaction data exported and analyzed
4. ✅ Statistical findings documented
5. ✅ Edge cases documented with on-chain proof
6. ✅ Week 2 summary written

**If any criteria not met:** Don't proceed to Week 3. Complete Week 2 first.

---

## Troubleshooting

**Agents not rating bidirectionally:**
- Verify base_agent.py has `rate_client()` and `rate_validator()` methods
- Check agent has AVAX for gas
- Verify ReputationRegistry address in .env

**Simulation script fails:**
- Check all agents are registered
- Verify AVAX balances sufficient
- Use `--dry-run` to test without transactions
- Check Fuji RPC is responsive

**Data analysis errors:**
- Verify CSV format matches expected columns
- Check for missing data fields
- Use pandas `.fillna()` for missing values

**Not finding edge cases:**
- Run more varied scenarios in simulation
- Include intentional bad actor scenarios
- Check transaction history for natural edge cases

---

## Week 2 Timeline

| Day | Tasks | Hours | Output |
|-----|-------|-------|--------|
| 1 | Deploy to all agents | 4 | All agents ready |
| 2 | Create simulation script | 4 | Script ready |
| 3 | Execute 100+ transactions | 4 | Transaction data |
| 4 | Analyze patterns | 4 | Statistical findings |
| 5 | Document edge cases | 4 | Edge case documentation |
| **Total** | | **20** | **Complete evidence package** |

---

**Next:** After completing Week 2, move to `contribution/week3/3.0-CHECKLIST.md` (Security Analysis)
